\BOOKMARK [0][]{Contents.0}{Contents}{}% 1
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{1.1 Motivation}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{1.2 State of the art}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.3}{1.3 Electromyography}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{1.4 Stationary signals}{chapter.1}% 6
\BOOKMARK [1][-]{section.1.5}{1.5 Non-stationary signals}{chapter.1}% 7
\BOOKMARK [2][-]{subsection.1.5.1}{1.5.1 Cause of non-stationarity in EMG signals}{section.1.5}% 8
\BOOKMARK [1][-]{section.1.6}{1.6 Thalmic Myo}{chapter.1}% 9
\BOOKMARK [1][-]{section.1.7}{1.7 IMU of the Myo Armband}{chapter.1}% 10
\BOOKMARK [1][-]{section.1.8}{1.8 Gesture Recognition}{chapter.1}% 11
\BOOKMARK [1][-]{section.1.9}{1.9 Armband positioning}{chapter.1}% 12
\BOOKMARK [0][]{chapter.2}{2 Methods}{}% 13
\BOOKMARK [1][-]{section.2.1}{2.1 Pipeline summary}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.2}{2.2 Data collection}{chapter.2}% 15
\BOOKMARK [1][-]{section.2.3}{2.3 Cross-Validation}{chapter.2}% 16
\BOOKMARK [1][-]{section.2.4}{2.4 Windowing}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.4.1}{2.4.1 Windowing in current work}{section.2.4}% 18
\BOOKMARK [1][-]{section.2.5}{2.5 Feature extraction}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.5.1}{2.5.1 Moving average}{section.2.5}% 20
\BOOKMARK [2][-]{subsection.2.5.2}{2.5.2 Root mean square}{section.2.5}% 21
\BOOKMARK [2][-]{subsection.2.5.3}{2.5.3 Short-time Fourier transform}{section.2.5}% 22
\BOOKMARK [2][-]{subsection.2.5.4}{2.5.4 Wavelet Analysis}{section.2.5}% 23
\BOOKMARK [2][-]{subsection.2.5.5}{2.5.5 Continuous wavelet transform}{section.2.5}% 24
\BOOKMARK [2][-]{subsection.2.5.6}{2.5.6 Discrete wavelet transform}{section.2.5}% 25
\BOOKMARK [3][-]{subsubsection.2.5.6.1}{2.5.6.1 Haar wavelet: An example of wavelet function}{subsection.2.5.6}% 26
\BOOKMARK [2][-]{subsection.2.5.7}{2.5.7 Feature extraction in current work}{section.2.5}% 27
\BOOKMARK [1][-]{section.2.6}{2.6 Training and classification}{chapter.2}% 28
\BOOKMARK [2][-]{subsection.2.6.1}{2.6.1 Forward selection, backward elimination}{section.2.6}% 29
\BOOKMARK [1][-]{section.2.7}{2.7 Artificial intelligence}{chapter.2}% 30
\BOOKMARK [2][-]{subsection.2.7.1}{2.7.1 Biological and artificial neural networks}{section.2.7}% 31
\BOOKMARK [2][-]{subsection.2.7.2}{2.7.2 Artificial neural networks}{section.2.7}% 32
\BOOKMARK [2][-]{subsection.2.7.3}{2.7.3 Deep learning}{section.2.7}% 33
\BOOKMARK [2][-]{subsection.2.7.4}{2.7.4 Deep learning architecture}{section.2.7}% 34
\BOOKMARK [2][-]{subsection.2.7.5}{2.7.5 Deep feed forward networks}{section.2.7}% 35
\BOOKMARK [2][-]{subsection.2.7.6}{2.7.6 Learning Conditional Statistics}{section.2.7}% 36
\BOOKMARK [2][-]{subsection.2.7.7}{2.7.7 Common Activation Functions}{section.2.7}% 37
\BOOKMARK [2][-]{subsection.2.7.8}{2.7.8 Identity Activation Function}{section.2.7}% 38
\BOOKMARK [2][-]{subsection.2.7.9}{2.7.9 Logistic Sigmoid}{section.2.7}% 39
\BOOKMARK [2][-]{subsection.2.7.10}{2.7.10 Hyperbolic Tangent}{section.2.7}% 40
\BOOKMARK [2][-]{subsection.2.7.11}{2.7.11 Rectified Linear Units}{section.2.7}% 41
\BOOKMARK [2][-]{subsection.2.7.12}{2.7.12 Softmax function}{section.2.7}% 42
\BOOKMARK [2][-]{subsection.2.7.13}{2.7.13 Minimization of the cost function}{section.2.7}% 43
\BOOKMARK [2][-]{subsection.2.7.14}{2.7.14 Backpropagation}{section.2.7}% 44
\BOOKMARK [2][-]{subsection.2.7.15}{2.7.15 Summary of training neural network}{section.2.7}% 45
\BOOKMARK [1][-]{section.2.8}{2.8 Data evaluation}{chapter.2}% 46
\BOOKMARK [0][]{chapter.3}{3 Results}{}% 47
\BOOKMARK [1][-]{section.3.1}{3.1 Parameter adjustment}{chapter.3}% 48
\BOOKMARK [1][-]{section.3.2}{3.2 Final evaluation}{chapter.3}% 49
\BOOKMARK [0][]{chapter.4}{4 Discussion}{}% 50
\BOOKMARK [1][-]{section.4.1}{4.1 Parameter Adjustment}{chapter.4}% 51
\BOOKMARK [2][-]{subsection.4.1.1}{4.1.1 Increase on the window step}{section.4.1}% 52
\BOOKMARK [2][-]{subsection.4.1.2}{4.1.2 Forward Selection, Backward Elimination: a hybrid approach}{section.4.1}% 53
\BOOKMARK [1][-]{section.4.2}{4.2 Evaluation results}{chapter.4}% 54
\BOOKMARK [0][]{chapter.5}{5 Conclusion}{}% 55
\BOOKMARK [1][-]{section.5.1}{5.1 Future Work}{chapter.5}% 56
\BOOKMARK [2][-]{subsection.5.1.1}{5.1.1 Size of data}{section.5.1}% 57
\BOOKMARK [2][-]{subsection.5.1.2}{5.1.2 Amount of features and reduction of the feature vector}{section.5.1}% 58
\BOOKMARK [2][-]{subsection.5.1.3}{5.1.3 Network Architectures}{section.5.1}% 59
\BOOKMARK [0][]{section*.10}{Bibliography}{}% 60
\BOOKMARK [0][]{section*.10}{List of Figures}{}% 61
\BOOKMARK [0][]{section*.10}{List of Tables}{}% 62
\BOOKMARK [0][]{appendix.A}{A Appendix}{}% 63
\BOOKMARK [1][-]{section.A.1}{A.1 List of Abbreviations}{appendix.A}% 64
